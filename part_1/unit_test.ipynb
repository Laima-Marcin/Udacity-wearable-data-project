{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Algorithm\n",
    "\n",
    "## Instructions\n",
    "1. From the **Pulse Rate Algorithm** Notebook you can do one of the following:\n",
    "   - Copy over all the **Code** section to the following Code block.\n",
    "   - Download as a Python (`.py`) and copy the code to the following Code block.\n",
    "2. In the bottom right, click the <span style=\"color:blue\">Test Run</span> button. \n",
    "\n",
    "### Didn't Pass\n",
    "If your code didn't pass the test, go back to the previous Concept or to your local setup and continue iterating on your algorithm and try to bring your training error down before testing again.\n",
    "\n",
    "### Pass\n",
    "If your code passes the test, complete the following! You **must** include a screenshot of your code and the Test being **Passed**. Here is what the starter filler code looks like when the test is run and should be similar. A passed test will include in the notebook a green outline plus a box with **Test passed:** and in the Results bar at the bottom the progress bar will be at 100% plus a checkmark with **All cells passed**.\n",
    "![Example](example.png)\n",
    "\n",
    "1. Take a screenshot of your code passing the test, make sure it is in the format `.png`. If not a `.png` image, you will have to edit the Markdown render the image after Step 3. Here is an example of what the `passed.png` would look like \n",
    "2. Upload the screenshot to the same folder or directory as this jupyter notebook.\n",
    "3. Rename the screenshot to `passed.png` and it should show up below.\n",
    "![Passed](passed.png)\n",
    "4. Download this jupyter notebook as a `.pdf` file. \n",
    "5. Continue to Part 2 of the Project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "nrtnppao4pm",
    "udacity_user_query": ""
   },
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in list(zip(data_fls, ref_fls))[:]:\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric \n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    '''Given a sample data file with PPG and 3 accelerometer channels and reference file with ground truth heart rates,\n",
    "       compute pulse rates every two seconds.\n",
    "       Parameters:\n",
    "           data_fl: .mat file containing PPG and X, Y, Z accelerometer data from Troika dataset\n",
    "           ref_fl: .mat file containing ground truth heart rates from Troika dataset\n",
    "       \n",
    "       Returns:\n",
    "           errors: numpy array with differences between predicted and reference heart rates\n",
    "           confidence: numpy array with confidence values for heart rate predictions\n",
    "    '''\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    \n",
    "    Fs = 125 # Troika data has sampling rate of 125 Hz\n",
    "    \n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    \n",
    "    winSize = 8*Fs # Ground truth BPM provided in 8 second windows\n",
    "    winShift = 2*Fs # Successive ground truth windows overlap by 2 seconds\n",
    "    \n",
    "    ref = sp.io.loadmat(ref_fl)\n",
    "    \n",
    "    errs = []\n",
    "    confs = []\n",
    "    \n",
    "    # For each 8 second window, compute a predicted BPM and confidence and compare to ground truth\n",
    "    offset = 0\n",
    "    for eval_window_idx in range(len(ref['BPM0'])):\n",
    "        \n",
    "        # Set verbose to True to visualize plot analysis\n",
    "        verbose = False\n",
    "        # verbose = True if eval_window_idx == 28 else False\n",
    "    \n",
    "        window_start = offset\n",
    "        window_end = winSize+offset\n",
    "        offset += winShift\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Win start,end: {window_start}, {window_end}\")\n",
    "        \n",
    "        ppg_window = ppg[window_start:window_end]\n",
    "        accx_window = accx[window_start:window_end]\n",
    "        accy_window = accy[window_start:window_end]\n",
    "        accz_window = accz[window_start:window_end]\n",
    "\n",
    "        pred, conf = AnalyzeWindow(ppg_window, accx_window, accy_window, accz_window, Fs=Fs, verbose=verbose)\n",
    "        \n",
    "        groundTruthBPM = ref['BPM0'][eval_window_idx][0]\n",
    "        if verbose:\n",
    "            print('Ground Truth BPM: ', groundTruthBPM)\n",
    "\n",
    "        predError = groundTruthBPM - pred\n",
    "        errs.append(predError)\n",
    "        confs.append(conf)\n",
    "\n",
    "    errors, confidence = np.array(errs), np.array(confs)\n",
    "    return errors, confidence\n",
    "\n",
    "def AnalyzeWindow(ppg, accx, accy, accz, Fs=125, verbose=False):\n",
    "    ''' Analyze a single 8 second window of PPG and Accelerometer data.\n",
    "        Parameters:\n",
    "            ppg: numpy array with ppg values\n",
    "            accx/y/z: numpy arrays with per-axis accelerometer data\n",
    "            Fs: sampling rate used by both PPG and accelerometer sensors\n",
    "            verbose: display plots and logging information.\n",
    "    \n",
    "        Returns:\n",
    "            prediction: Tuple of (BPM prediction, confidence) for this window.\n",
    "    '''\n",
    "    \n",
    "    ppg_bandpass = BandpassFilter(ppg, fs=Fs)\n",
    "    accx_bandpass = BandpassFilter(accx, fs=Fs)\n",
    "    accy_bandpass = BandpassFilter(accy, fs=Fs)\n",
    "    accz_bandpass = BandpassFilter(accz, fs=Fs)\n",
    "    \n",
    "    # Aggregate accelerometer data into single signal\n",
    "    \n",
    "    accy_mean = accy-np.mean(accy_bandpass) # Center Y values\n",
    "    acc_mag_unfiltered = np.sqrt(accx_bandpass**2+accy_mean**2+accz_bandpass**2)\n",
    "    acc_mag = BandpassFilter(acc_mag_unfiltered, fs=Fs)\n",
    "    \n",
    "    peaks = find_peaks(ppg_bandpass, height = 10, distance=35)[0]\n",
    "    \n",
    "    if verbose:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4))\n",
    "        ax1.title.set_text('Signal with Time Domain FindPeaks()')\n",
    "        ax1.plot(ppg_bandpass)\n",
    "        ax1.plot(peaks, ppg_bandpass[peaks], \"x\")\n",
    "        \n",
    "        ax2.title.set_text('Aggregated Accelerometer Data')\n",
    "        ax2.plot(acc_mag, color=\"purple\")\n",
    "        plt.show()\n",
    "        \n",
    "    # Use FFT length larger than the input signal size for higher spectral resolution.\n",
    "    fft_len=len(ppg_bandpass)*4\n",
    "\n",
    "    # Create an array of frequency bins\n",
    "    freqs = np.fft.rfftfreq(fft_len, 1 / Fs) # bins of width 0.12207031\n",
    "\n",
    "    # The frequencies between 40 BPM and 240 BPM Hz\n",
    "    low_freqs = (freqs >= (40/60)) & (freqs <= (240/60))\n",
    "    \n",
    "    mag_freq_ppg, fft_ppg = FreqTransform(ppg_bandpass, freqs, low_freqs, fft_len)\n",
    "    mag_freq_acc, fft_acc = FreqTransform(acc_mag, freqs, low_freqs, fft_len)\n",
    "    \n",
    "    peaks_ppg = find_peaks(mag_freq_ppg, height=30, distance=1)[0]\n",
    "    peaks_acc = find_peaks(mag_freq_acc, height=30, distance=1)[0]\n",
    "    \n",
    "    # Sort peaks in order of peak magnitude\n",
    "    sorted_freq_peaks_ppg = sorted(peaks_ppg, key=lambda i:mag_freq_ppg[i], reverse=True)\n",
    "    sorted_freq_peaks_acc = sorted(peaks_acc, key=lambda i:mag_freq_acc[i], reverse=True)\n",
    "    \n",
    "    # Use the frequency peak with the highest magnitude, unless the peak is also present in the accelerometer peaks.\n",
    "    use_peak = sorted_freq_peaks_ppg[0]\n",
    "    for i in range(len(sorted_freq_peaks_ppg)):\n",
    "        # Check nearest two peaks also\n",
    "        cond1 = sorted_freq_peaks_ppg[i] in sorted_freq_peaks_acc\n",
    "        cond2 = sorted_freq_peaks_ppg[i]-1 in sorted_freq_peaks_acc\n",
    "        cond3 = sorted_freq_peaks_ppg[i]+1 in sorted_freq_peaks_acc\n",
    "        if cond1 or cond2 or cond3:\n",
    "            continue\n",
    "        else:\n",
    "            use_peak = sorted_freq_peaks_ppg[i]\n",
    "            break\n",
    "\n",
    "    chosen_freq = freqs[low_freqs][use_peak]\n",
    "    prediction = chosen_freq * 60\n",
    "    confidence = CalcConfidence(chosen_freq, freqs, fft_ppg)\n",
    "    \n",
    "    if verbose:\n",
    "        plt.title(\"PPG Frequency Magnitude\")\n",
    "        plt.plot(mag_freq_ppg)\n",
    "        plt.plot(peaks_ppg, mag_freq_ppg[peaks_ppg], \"x\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(\"ACC Frequency Magnitude\")\n",
    "        plt.plot(mag_freq_acc, color=\"purple\")\n",
    "        plt.plot(peaks_acc, mag_freq_acc[peaks_acc], \"x\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"PPG Freq Peaks: \", peaks_ppg)\n",
    "        print(\"ACC Freq Peaks: \", peaks_acc)\n",
    "        \n",
    "        print(\"PPG Freq Peaks Sorted: \", sorted_freq_peaks_ppg)\n",
    "        print(\"ACC Freq Peaks Sorted: \", sorted_freq_peaks_acc)\n",
    "        print(\"Use peak: \", use_peak)\n",
    "        print(f\"Predicted BPM: {prediction}, {chosen_freq} (Hz), Confidence: {confidence}\")        \n",
    "        \n",
    "    return (prediction, confidence)\n",
    "\n",
    "def BandpassFilter(signal, fs):\n",
    "    '''Bandpass filter the signal between 40 and 240 BPM'''\n",
    "    \n",
    "    # Convert to Hz\n",
    "    lo, hi = 40/60, 240/60\n",
    "    \n",
    "    b, a = sp.signal.butter(3, (lo, hi), btype='bandpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def FreqTransform(x, freqs, low_freqs, fft_len):\n",
    "    '''Compute and return FFT and magnitude of FFT for given low frequencies\n",
    "        Parameters:\n",
    "            x: numpy array input signal to transform\n",
    "            freqs: full list of FFT frequency bins\n",
    "            low_freqs: low frequency bins between 40 BPM and 240 BPM\n",
    "            fft_len: length of FFT to compute\n",
    "            \n",
    "        Returns:\n",
    "            mag_freq_x: magnitude of lower frequencies of the FFT transformed signal\n",
    "            fft_x: FFT of normalized input signal\n",
    "    '''\n",
    "    \n",
    "    # Take an FFT of the normalized signal\n",
    "    norm_x = (x - np.mean(x))/(max(x)-min(x))\n",
    "    fft_x = np.fft.rfft(norm_x, fft_len)\n",
    "\n",
    "    # Calculate magnitude of the lower frequencies\n",
    "    mag_freq_x = np.abs(fft_x)[low_freqs]\n",
    "    \n",
    "    return mag_freq_x, fft_x\n",
    "\n",
    "def CalcConfidence(chosen_freq, freqs, fft_ppg):\n",
    "    '''Calculates a confidence value for a given frequency by computing\n",
    "       the ratio of energy concentrated near that frequency compared to the full signal.\n",
    "       Parameters:\n",
    "           chosen_freq: frequency prediction for heart rate.\n",
    "           freqs: full list of FFT frequency bins\n",
    "           fft_ppg: FFT of normalized PPG signal\n",
    "       \n",
    "       Returns:\n",
    "           conf_val: Confidence value for heart rate prediction.\n",
    "    '''\n",
    "    win = (40/60.0)\n",
    "    win_freqs = (freqs >= chosen_freq - win) & (freqs <= chosen_freq + win)\n",
    "    abs_fft_ppg = np.abs(fft_ppg)\n",
    "    \n",
    "    # Sum frequency spectrum near pulse rate estimate and divide by sum of entire spectrum\n",
    "    conf_val = np.sum(abs_fft_ppg[win_freqs])/np.sum(abs_fft_ppg)\n",
    "    \n",
    "    return conf_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "grader_mode": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
